{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from zipfile import ZipFile\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "testing the reading from a zip file and extracting just one file "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "z = ZipFile('/home/nfarrugi/bigdisk2/new/dropbox/SilentCitiesData/0003/Sebastien Puechmaille - 003_01.zip')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "filelist = z.namelist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "filelist[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['20200327_194000.WAV',\n",
       " '20200327_195000.WAV',\n",
       " '20200327_200000.WAV',\n",
       " '20200327_201000.WAV',\n",
       " '20200327_202000.WAV',\n",
       " '20200327_203000.WAV',\n",
       " '20200327_204000.WAV',\n",
       " '20200327_205000.WAV',\n",
       " '20200327_210000.WAV',\n",
       " '20200327_211000.WAV']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pipeline\n",
    "--\n",
    "\n",
    "We will do this in the following steps : \n",
    "1. For each folder or dropbox, search for an existing folder on bigdisk1 or bigdisk2. \n",
    "2. If the folder is not founddd, this is a new site. \n",
    "3. Parse the list of new sites and put them on bigdisk2, extract them flat. Save the list of new sites as sites for which we will need to restart \"metadata_file\"\n",
    "4. Parse all the other archives by checking their file list, compare with the csv of the corresponding site, copy if needed. If ANY copy is done, add the corresponding site to the list of sites to update. \n",
    "5. Relaunch metadata_file.py for all the sites that have been updated\n",
    "6. Relaunch metadata_site.py \n",
    "7. Relaunch audio_processing.py for all the sites that have been updated"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. For each folder or dropbox, search for an existing folder on bigdisk1 or bigdisk2. \n",
    "2. If the folder is not found, this is a new site. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "bigdisk1 = '/home/nfarrugi/bigdisk1'\n",
    "bigdisk2 = '/home/nfarrugi/bigdisk2'\n",
    "\n",
    "dropboxfolder = '/home/nfarrugi/bigdisk2/new/dropbox/SilentCitiesData/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "newsites = []\n",
    "bigdisk1sites = []\n",
    "bigdisk2sites = []\n",
    "\n",
    "for curdir in os.listdir(dropboxfolder):\n",
    "    if os.path.isdir(os.path.join(bigdisk1,'silentcities',curdir)):\n",
    "        print(f\"{curdir} found on bigdisk1\")\n",
    "    elif os.path.isdir(os.path.join(bigdisk2,'silentcities',curdir)):\n",
    "        print(f\"{curdir} found on bigdisk2\")\n",
    "    else:\n",
    "        newsites.append(curdir)\n",
    "        print(f\"{curdir} is a new site\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0308 is a new site\n",
      "0334 is a new site\n",
      "0145 found on bigdisk1\n",
      "0149 found on bigdisk1\n",
      "0137 found on bigdisk1\n",
      "0098 found on bigdisk1\n",
      "0238 found on bigdisk1\n",
      "0167 found on bigdisk1\n",
      "0342 found on bigdisk2\n",
      "0142 found on bigdisk1\n",
      "0233 found on bigdisk2\n",
      "0096 found on bigdisk1\n",
      "0108 found on bigdisk1\n",
      "0131 found on bigdisk1\n",
      "0196 found on bigdisk1\n",
      "0270 found on bigdisk1\n",
      "0315 found on bigdisk2\n",
      "0344 found on bigdisk1\n",
      "0141 found on bigdisk1\n",
      "0361 found on bigdisk1\n",
      "0286 found on bigdisk2\n",
      "0015 is a new site\n",
      "0247 found on bigdisk1\n",
      "0057 found on bigdisk1\n",
      "0082 found on bigdisk1\n",
      "0050 found on bigdisk2\n",
      "0243 found on bigdisk2\n",
      "0201 found on bigdisk2\n",
      "0324 found on bigdisk1\n",
      "0014 found on bigdisk1\n",
      "0181 found on bigdisk1\n",
      "0115 found on bigdisk1\n",
      "0090 found on bigdisk1\n",
      "0176 found on bigdisk1\n",
      "0039 is a new site\n",
      "0213 found on bigdisk1\n",
      "0236 found on bigdisk1\n",
      "0148 found on bigdisk1\n",
      "0268 found on bigdisk1\n",
      "0296 found on bigdisk1\n",
      "0256 found on bigdisk1\n",
      "0322 is a new site\n",
      "0151 found on bigdisk1\n",
      "0085 found on bigdisk1\n",
      "0349 found on bigdisk1\n",
      "0228 found on bigdisk1\n",
      "0347 found on bigdisk2\n",
      "0306 found on bigdisk2\n",
      "0025 found on bigdisk1\n",
      "0351 found on bigdisk1\n",
      "0408 found on bigdisk1\n",
      "0072 found on bigdisk1\n",
      "0377 found on bigdisk1\n",
      "0092 found on bigdisk1\n",
      "0016 found on bigdisk1\n",
      "0198 found on bigdisk1\n",
      "0214 found on bigdisk1\n",
      "0105 found on bigdisk1\n",
      "0234 found on bigdisk2\n",
      "0325 found on bigdisk1\n",
      "0358 found on bigdisk2\n",
      "0028 found on bigdisk1\n",
      "0374 found on bigdisk1\n",
      "indiv is a new site\n",
      "0121 found on bigdisk1\n",
      "0003 found on bigdisk1\n",
      "0112_A is a new site\n",
      "0237 found on bigdisk1\n",
      "0202 found on bigdisk1\n",
      "0360 found on bigdisk2\n",
      "0287 found on bigdisk1\n",
      "0170 found on bigdisk1\n",
      "0382 is a new site\n",
      "0069 found on bigdisk1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Parse the list of new sites and put them on bigdisk2, extract them flat. Save the list of new sites as sites for which we will need to restart \"metadata_file\"\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def extract_list_from_zip(zipfile,destdir,filelist=None):\n",
    "    ###Â filelist is a subset (potentially all) from the list of files in zipfile\n",
    "    ### If not, take the whole list of files from the zip\n",
    "\n",
    "    os.makedirs(destdir,exist_ok=True)\n",
    "\n",
    "    z = ZipFile(zipfile)\n",
    "\n",
    "    if filelist is None:\n",
    "        filelist = z.namelist()\n",
    "        print(\"Extracting all files...\")\n",
    "    \n",
    "    print(f\"Extracting {len(filelist)}files\")\n",
    "\n",
    "    for curfile in filelist:\n",
    "        \n",
    "        # In case in the filelist there are paths\n",
    "        filenameonly = os.path.split(curfile)[1]\n",
    "\n",
    "        # extract a specific file from the zip container\n",
    "        f = z.open(curfile)\n",
    "\n",
    "        # save the extracted file \n",
    "        content = f.read()\n",
    "        f = open(os.path.join(destdir,filenameonly), 'wb')\n",
    "        f.write(content)\n",
    "        f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def check_folder_zip_copy(zipfile,destfolder)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "162674de85ec75a69b4194fad12dddd6d22a1077c9cd2db952848c666203d6f8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}